[TOC]

#### 实验准备

在lab1可以运行的前提下，确保makefile里面的qemu可以工作，如果makefile被修改错了，粘贴原始lab2里面的makefile进行覆盖。

中间可能提示fatal error: -fuse-linker-plugin, but liblto_plugin.so not found，需要在工具链目录下找到 liblto_plugin.so.0.0.0 复制成一份 liblto_plugin.so 顺利解决

开始实验：修改makefile里面的opensbi的版本为正确版本,修改bios对应文件为GitHub下载下来的文件:
<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231013183323996.png" alt="image-20231013183323996" style="zoom:50%;" />

此时可以make qemu应该可以看到大量的kkkk
<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231013183845696.png" alt="image-20231013183845696" style="zoom:50%;" />
为什么出现kkk呢，因为debug的panic.c里面故意设置了一个for循环输出k，把它注释掉就行

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231013184347083.png" alt="image-20231013184347083" style="zoom: 33%;" />

此时再make qemu,可以看到opensbi被启动了：
<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231013184824216.png" alt="image-20231013184824216" style="zoom:50%;" />

然后了解一下库函数list后面有用
![image-20231013213100715](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231013213100715.png)

list是一个双向链表，可以被struct list_entry理解为node,又把struct list_entry简写为list_entry_t

其中这里的add很迷，__list_add是把elm插入节点prev和next之间。list_add_after是把elm插入listelm和listelm->next之间，和list_add一模一样。而list_add_before是把elm插入listelm和listelm->pre之间。init是让前后指针指向自己。

__list_del是让pre和next指向彼此，list_del是删掉一个元素，list_del_init是删掉元素，让它自己指向自己，list_empty通过是否指向自己判断是不是空的，list_prev和list_next是获取list前后元素的接口。
为了测试list，这里写了一个testlist放在test文件夹里面
<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231013214915889.png" alt="image-20231013214915889" style="zoom:50%;" />

可以实现基本的插入删除

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231013214948482.png" alt="image-20231013214948482" style="zoom:50%;" />

#### 对于启动过程的理解

和lab1是一致的，刚开始启动在0x1000,之后跳转到0x80000000,这一段执行力opensbi程序，相当于bios，然后跳转到0x80200000【此时所有的输出opensbi完毕】,去执行内核程序。

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231014223826912.png" alt="image-20231014223826912" style="zoom:67%;" />

而内核程序的执行顺序是：先执行entry.S

但是这一次entry.S和lab1有了很大不一样，在此之前，我们需要阅读实验手册：
<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231014231150823.png" alt="image-20231014231150823" style="zoom:25%;" />

###### **第一段**

说明了如果没有适当的物理内存管理，所有程序，无论是内核还是用户程序，都将共享同一个地址空间，从而产生冲突。

解决方法是引入一个“翻译”机制，其中程序使用的虚拟地址在访问物理内存之前必须被“翻译”成物理地址。

如果为每个字节都提供一个单独的翻译项，这个字典将变得非常大，这将导致效率低下。

为了提高效率，内存被分组到固定大小的块中，这些块称为“页”。这个映射是以页为单位的。

###### **第二段**

说明了使用的是 RISCV 架构下的 sv39 页表机制。每页大小为 4KB，即 4096 字节。
页表是一个"词典"，它存储了虚拟地址（程序看到和使用的地址）与物理地址（真实内存硬件上的地址）之间的映射。
虚拟页的数量可能远大于物理页的数量，这意味着并非所有的虚拟地址都有与之对应的物理地址。
在 sv39 页表机制中，物理地址有 56 位，而虚拟地址有 39 位。尽管虚拟地址有 64 位，但只有低 39 位是有效的。位于 63−39 位的值必须与第 38 位的值相同，否则这个虚拟地址被认为是非法的，访问它会触发异常。
无论物理还是虚拟地址，最后的 12 位代表页内偏移，即这个地址在其所在页的位置。因为一个页大小是4B,2^12，也就是页内字节地址需要12位表达。除了最后 12 位，前面的位数代表物理页号或虚拟页号。

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231014234907868.png" alt="image-20231014234907868" style="zoom: 33%;" />

###### **第三段**
lab2和lab1启动有所不同

- 在启动时，bootloader 不再像 lab1 那样直接调用 kern_init 函数。
- 它首先调用 entry.S 中的 kern_entry 函数，其任务是为 kern_init 函数建立良好的 C 语言运行环境，设置堆栈，并临时建立段映射关系，为后续的分页机制建立做准备。
- 完成这些后，才调用 kern_init 函数。
- kern_init 函数首先完成一些输出和检查 lab1 的实验结果，然后开始物理内存管理的初始化，即调用 pmm_init 函数。
- 完成物理内存管理后，它会进行中断和异常的初始化，调用 pic_init 函数和 idt_init 函数。

###### **第四段**
一个页表项是用来描述一个虚拟页号如何映射到物理页号的。这个“词典”存储在内存中，由固定格式的“词条”（即页表项）组成。

在 sv39 中，每个页表项大小为 8 字节（64 位）。

- 位 63-54：保留位
- 位 53-10：物理页号（共 44 位）
- 位 9-0：映射的状态信息（共 10 位）

![image-20231014235953151](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231014235953151.png)

- RSW：为 S Mode 的应用程序预留的两位，可用于拓展。

- D（Dirty）：标识页表项是否已被写入。

- A（Accessed）：标识页表项是否已被读取或写入。

- G（Global）：标识页表项是否为“全局”的，即所有的地址空间都包含这一项。

- U（User）：标识是否允许用户态程序使用该页表项进行映射。

- R,W,X：分别标识该页是否可读、可写、可执行。

- **根据 X,W,R 的不同组合，映射的类型有：**

  ![image-20231015000222291](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015000222291.png)

###### **第五段**
普通页表里面存储了虚拟页号对应的物理页号【类似于一个数组，虚拟页号作为下标，查找到物理页号】。
![image-20231015102033682](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015102033682.png)

多级页表是为了解决当虚拟地址空间非常大时，单级页表可能会非常浪费空间的问题。【例如对于39位的虚拟地址,39-12=27，可以分成2^27个(虚拟))页，每个虚拟页都要映射到一个物理页，而存储这个物理页号需要8bit，意味着仅仅是存储一个页表，居然都要1GB,页表还是存储在内存里的，这显然不现实】

为什么二级页表更高效:

如果是只有一级页表，它必须是连续的，就像一个数组，用虚拟页号作为索引，得到物理页号，就导致了只有开始和结束部分的虚拟地址被使用时，也必须构建一个很大的数组。

但是如果是多级页表，就可以不连续，假设要找到二级页表中虚拟页号`0x100`对应的物理页号`0x1234`的映射关系,会使用虚拟地址的某些高位,在一级页表中查找。这些高位会告诉你该虚拟地址可能位于哪个二级页表中【物理地址】。如果二级页表只有开头和结尾被使用，也只会建立两个页表项，可以紧挨在一起。
![image-20231015102848211](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015102848211.png)

###### **第六段**

`satp`，即Supervisor Address Translation and Protection Register，根页表的起始地址寄存器。

其中高4位还存储了页表的模式
![image-20231015105859915](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015105859915.png)

###### **第七段**
TLB 快表（**Translation Lookaside Buffer**）：类似于页表的cache

修改satp（尤其是PNN段）或者修改页表项，都会导致TLB不同步，可以通过`sfence.vma`指令来刷新TLB，没有参数，它会刷新整个TLB。如果提供了一个虚拟地址作为参数，则只会刷新该地址的映射。
###### **entry.S:设置satp寄存器**
在lab1当中， entry.S的工作特别简单，就是分配栈空间，设置栈指针，跳转到kern_init。而内核程序是放在0x8020 0000上面的，

而lab2目标是将内核代码从物理地址空间迁移到虚拟地址空间，并让它运行在一个特定的高地址空间，即`0xffffffffc0200000`。

在0xffffffffc0200000打上断点，会发现它对应着entry.S的第一句话,也就是说执行完启动程序opensbi【还是在0x8000 0000 ~ 0x8020 0000】之后，去执行虚拟地址0xffffffffc0200000的内容。

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015115748828.png" alt="image-20231015115748828" style="zoom:50%;" />

整个内核加载在虚拟地址0xffffffffc0200000开头的位置上,其中0xffffffffc0200036对应着kern_init

![image-20231015121545073](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015121545073.png)

![image-20231015121811600](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015121811600.png)

而执行kern_init之前，还会执行0xffffffffc0200000~0xffffffffc0200036这一段，这一段就是entry.S
![image-20231015120045160](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015120045160.png)

而要理解entry.S,还需要理解**lui**，将立即数加载到寄存器高位，寄存器低位置为0.
**%hi**:取一个地址的高20位**li**将立即数加载到寄存器，**srli**:将一个寄存器逻辑右移i位。**Sv39**:risc-V虚拟内存调用模式，有39位虚拟内存地址，**csrw**写入csr寄存器。

可以看到，satp最高级页表起始处的物理地址是0x80205000,也就是在内核空间中，在内存中，但是刚开始我们不知道它的物理地址，只知道虚拟地址，可以用%hi(boot_page_table_sv39)获取。问题是知道物理地址呢，可以线性映射，内核起始处的物理地址是0x8020 0000,但是虚拟地址是0xffffffffc0200000，中间差了0xffffffff40000000，因此，根页表的虚拟地址0xffffffffc0205000-0xffffffff40000000就是物理地址0x80205000。
这就是为什么要用li      t1, 0xffffffffc0000000 - 0x80000000算偏移量，sub     t0, t0, t1算出根页表的物理地址，而我们知道物理地址到物理页号，还需要去掉末尾12位，所以srli    t0, t0, 12才是根页表的物理页号。此时t0的高位是0.
之前说过stap最高位记录了模式
![image-20231015123716760](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015123716760.png)

li      t1, 8 << 60表示0100后面有60个0，恰好对应sv39模式【39位虚拟内存】

or      t0, t0, t1，将t0的高4位置为0100，此时t0高位记录模式，低位记录根页表物理地址，表示的就是satp

csrw    satp, t0,已经可以将t0存入satp了
之前说过，修改satp相当于修改了整个页表，需要刷新快表：csrw    satp, t0
综上所述，**这么一大段的效果就是：算出satp寄存器的正确值。**
###### entry.S:设置sp后准备跳转

而下一段：

![image-20231015124732475](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015124732475.png)

就干了两件事：1设置sp，因为被sp标记的是栈空间。
2跳转到kern/init.c/kern_init()函数，只是算出这个地址要分成高低两次加载
###### entry.S其他设置

.align PGSHIFT页表需要对齐到一个页的起始，一个页有4K，12位

.zero 8 * 511 前511个页表项都是空的，一个页表项有8个bit,存储了对应的物理地址
映射是从0xffffffff_c0000000 map to 0x80000000 ，这就是为什么内核的物理内存在0x80020000，而虚拟内存在0xffffffff_c0200000

###### kern_init的代码

![image-20231015130559704](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015130559704.png)

从外部获取到数据段结束位置和内核结束位置，将数据段结束位置到内核结束位置之间部分0xffffffffc0206010` 到 `0xffffffffc0206070 ，通常是bss段设置为0.

初始化啊输出控制台cons_init
输出一句话(THU.CST) os is loading ...
print_kerninfo()输出内核信息：

```c
Special kernel symbols:
  entry  0xffffffffc0200036 (virtual)
  etext  0xffffffffc02017fa (virtual)
  edata  0xffffffffc0206010 (virtual)
  end    0xffffffffc0206070 (virtual)
Kernel executable memory footprint: 25KB

```

![image-20231015132437646](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015132437646.png)
初始化中断向量表,执行了trap.c里面的idt_init()【中断描述表初始化】，定时发生中断，而中断时pc指向stvc里面的处理程序，处理程序对应trapentry.S里面的all_trap,先保存寄存器，跳转处理程序，恢复寄存器。处理程序又写在trap.c里面，这里要复制lab1的处理方式，输出10个kick之后停止。
clock_init();  // 之后才会定时有时钟中断，注意把关闭程序也引入。

intr_enable();  // enable irq interrupt允许外部中断

pmm_init();这一句话才是本实验的重点，可以看到，他会执行pmm.c的以下操作：

![image-20231015132524651](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015132524651.png)

首先来分析kern/mm/default_pmm.c,首先要理解单词的意思，kern:kernel

mm: **memory management**内存管理

pmm:**physical memory management**物理内存管理，区别于虚拟内存管理vmm

###### pmm流程分析

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015144833953.png" alt="image-20231015144833953" style="zoom:50%;" />

pmm.c/pmm_init()**调用init_pmm_manager()**
![image-20231015144928082](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015144928082.png)

选中要调用的管理方式![image-20231015145123700](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015145123700.png)，可以是default或者是bestfit,输出它的名字![image-20231015145311490](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015145311490.png)，然后让它初始化
**调用page_init()**

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015145721391.png" alt="image-20231015145721391" style="zoom:50%;" />

这一段确定了内核的物理内存的开始和结束位置，内存的大小，并且控制台里还输出了它

![image-20231015145840384](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015145840384.png)
可以看到内核的物理内存是从0x8020000开始的【和过去一样】，从0x87ffffff结束的

调用**check_alloc_page();![image-20231015150144548](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015150144548.png)**

调用内存管理器（default的或者是best的进行测试），如果中间没有报错，视为成功，输出成功。![image-20231015150419269](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015150419269.png)
最后还输出了根页表的物理地址和虚拟地址。
![image-20231015150513191](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015150513191.png)







#### 练习1：理解first-fit 连续物理内存分配算法（思考题）

first-fit 连续物理内存分配算法作为物理内存分配一个很基础的方法，需要同学们理解它的实现过程。请大家仔细阅读实验手册的教程并结合`kern/mm/default_pmm.c`中的相关代码，认真分析default_init，default_init_memmap，default_alloc_pages， default_free_pages等相关函数，并描述程序在进行物理内存分配的过程以及各个函数的作用。
请在实验报告中简要说明你的设计实现过程。请回答如下问题：

你的first fit算法是否有进一步的改进空间？

##### 对于流程的理解

在defualt_pmm.h里面可以看出，![image-20231015154342352](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015154342352.png)
默认内存管理器default_pmm_manager就是内存管理器pmm_manager,但是这里有具体的名字，和方法的名字。类似于c++的子类,属于用c语言实现类似c++子类的技巧。
![image-20231015154600033](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015154600033.png)

在![image-20231015155056099](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015155056099.png)pmm_manager->check的时候，执行的实际上是
default_check,而default_check里面又表用来basic_check，总体上进行了一些测试。

##### 对于空闲页块链表freelist的理解

然后要理解什么是free_area_t
![image-20231014152212467](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231014152212467.png)
free_area_t是freelist【最好的名字叫"**空闲页块链表**"】nr_free和空闲页数的结合

**页块是连续的若干页，一页一般有4k**

其中freelist是一个链表(开头)，将**页块**链接在一起

nr_free记录的是整个freelist这么多个页块里面，**空闲页的总数**

![image-20231014152304802](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231014152304802.png)

![30e555dcb62f2c5faaa575c31d4fdf8](C:\Users\86157\Documents\WeChat Files\wxid_54bh66rc4gc222\FileStorage\Temp\30e555dcb62f2c5faaa575c31d4fdf8.jpg)

##### 对于default_init的理解
初始化操作，free_list链表头尾指向自己(调用的是list.h里面的初始化函数)，然后把nr_free计数为0

![image-20231014153009834](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231014153009834.png)

此时表示的状态是：空闲页块一个没有，空闲页也一个没有。
![image-20231015152716966](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015152716966.png)

##### 对于页块page的理解

还要理解page是什么，page来自于memlayout.h【内存结构】

**在一个页块头部的页，property=0~n，表示这个页块内的空闲页数,此时page可以代表一个页块**
**其他的页property=0,page理解为一个普通的页**

![image-20231014153948267](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231014153948267.png)
ref： 通常表示页被进程等引用的次数

flag表示页的状态，其中有两个重要状态

**PG_reserved**:

- 当这个标志被设置（即为1）时，意味着这个页是为内核保留的，不能用于常规的页面分配或释放。

**PG_property**:

相当于在问property是否不为0？

- 当这个标志被设置（即为1）时，property不为0，这个页在页块头部，被理解为页块。
- 否则有两种可能：1这个页在页块头部，但是该页块内部的页被分配完了。2该页不在页块头部。

page_link对应着freelist

![93ece7aad99b2c2ce92e9bc2c0194fc](C:\Users\86157\Documents\WeChat Files\wxid_54bh66rc4gc222\FileStorage\Temp\93ece7aad99b2c2ce92e9bc2c0194fc.jpg)

##### 对于default_init_memmap的理解

![image-20231015183616489](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015183616489.png)

![427d9f73086a2434408e184d3be14df](C:\Users\86157\Documents\WeChat Files\wxid_54bh66rc4gc222\FileStorage\Temp\427d9f73086a2434408e184d3be14df.jpg)

![image-20231015184132028](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015184132028.png)

注意，freelist链接的只是页块的第一个页的page_link
![e48476be403310b63bb6730e587dd37](C:\Users\86157\Documents\WeChat Files\wxid_54bh66rc4gc222\FileStorage\Temp\e48476be403310b63bb6730e587dd37.jpg)

页表不为空，按照base页的地址插入
![a2228696123a75b3671de6b81dd45b9](C:\Users\86157\Documents\WeChat Files\wxid_54bh66rc4gc222\FileStorage\Temp\a2228696123a75b3671de6b81dd45b9.jpg)

##### 对于default_alloc_pages的理解

![image-20231015194558279](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015194558279.png)

![459ea9d8dd09eecda28669f172f0122](C:\Users\86157\Documents\WeChat Files\wxid_54bh66rc4gc222\FileStorage\Temp\459ea9d8dd09eecda28669f172f0122.jpg)

![image-20231015201909918](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015201909918.png)

![26c2b42ab6fd6c3680cc7269b30642d](C:\Users\86157\Documents\WeChat Files\wxid_54bh66rc4gc222\FileStorage\Temp\26c2b42ab6fd6c3680cc7269b30642d.jpg)

##### 对于default_free_pages的理解：

![image-20231015203537929](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015203537929.png)

![160e3ec7278572500356eeaa419572b](C:\Users\86157\Documents\WeChat Files\wxid_54bh66rc4gc222\FileStorage\Temp\160e3ec7278572500356eeaa419572b.jpg)
向前合并
![image-20231015204945569](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015204945569.png)

![](C:\Users\86157\Documents\WeChat Files\wxid_54bh66rc4gc222\FileStorage\Temp\482de8c6fbb3809ca17ebdf8b63ade4.jpg)

向后合并

![image-20231015205542988](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015205542988.png)

![73f9e9166362b2299005fa3eae51070](C:\Users\86157\Documents\WeChat Files\wxid_54bh66rc4gc222\FileStorage\Temp\73f9e9166362b2299005fa3eae51070.jpg)

##### 优化方案

**伙伴系统（Buddy System）**: 它将内存分成大小为2的幂的块，并尝试满足内存请求的最接近的块大小。好处是减少内存碎片。

**延迟合并（Deferred Coalescing）**: 而不是立即合并空闲块，可以延迟合并直到有需求或系统处于低负载状态。

**内存碎片**: 在default_alloc_pages里面，当我们需要n页的时候，必须要找到一个至少有n页的页块，不一定能满足，但是可能有很多碎片加起来是够的。因此我们可以考虑利用这些内存碎片。


#### 练习2：实现 Best-Fit 连续物理内存分配算法（需要编程）

在完成练习一后，参考kern/mm/default_pmm.c对First Fit算法的实现，编程实现Best Fit页面分配算法，算法的时空复杂度不做要求，能通过测试即可。
请在实验报告中简要说明你的设计实现过程，阐述代码是如何对物理内存进行分配和释放，并回答如下问题：

你的 Best-Fit 算法是否有进一步的改进空间？

##### default_init

这一段best fit和default fit没有差别
free_area表示一大块内存空间，初始化时没有空的内存，freelist里面是空的,可用的内存大小为0

![image-20231014183957394](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231014183957394.png)

##### default_init_memmap

###### 代码填空1

这里和default完全一样

内存页框的标志位置为0，表示free
![image-20231014184336800](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231014184336800.png)

###### 代码填空2

default也是一样的，

<img src="C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231014184740033.png" alt="image-20231014184740033" style="zoom: 67%;" />

效果也是相同的：
![image-20231014184905357](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231014184905357.png)

也就是说best-fit的效果需要后面的函数才能体现
###### 代码填空3

default的逻辑是：![image-20231014194120925](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231014194120925.png)

在free list里面逐个遍历页块，找到第一个大小超过或等于了n（我们需要的页块大小）的页块返回
![image-20231014194048304](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231014194048304.png) 

修改之后的逻辑是，找到第一个大小足够的页块时，先不要返回，因为后面可能会有更合适的，把页块大小存储下来，如果后面页块大小比这个还小，就选取他，最后就可以挑选到大小>=n的页块中最小的页块，也就是最合适的。

如果所有页块都小于n，返回空，并且min_size初始值是页块的大小极限，足够大，不会有逻辑问题。

###### 代码填空4

这一段和default一样

![image-20231014195203977](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231014195203977.png)

###### 代码填空5

这一段也和default一样
![image-20231014200735039](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231014200735039.png)

###### 通过验证

![image-20231015213155098](C:\Users\86157\AppData\Roaming\Typora\typora-user-images\image-20231015213155098.png)

##### 优化方案

**使用更好的数据结构**: 使用如平衡树、跳表等可以在O(log n)时间内查找、插入和删除的数据结构，可以提高某些操作的效率。

**伙伴系统（Buddy System）**: 这种方法在请求分配和释放内存时使用特定的算法来避免内存碎片。它将内存分成大小为2的幂的块，并尝试满足内存请求的最接近的块大小。



#### 扩展练习Challenge：buddy system（伙伴系统）分配算法（需要编程）

Buddy System算法把系统中的可用存储空间划分为存储块(Block)来进行管理, 每个存储块的大小必须是2的n次幂(Pow(2, n)), 即1, 2, 4, 8, 16, 32, 64, 128...

 -  参考[伙伴分配器的一个极简实现](http://coolshell.cn/articles/10427.html)， 在ucore中实现buddy system分配算法，要求有比较充分的测试用例说明实现的正确性，需要有设计文档。

#### 扩展练习Challenge：任意大小的内存单元slub分配算法（需要编程）

slub算法，实现两层架构的高效内存单元分配，第一层是基于页大小的内存分配，第二层是在第一层基础上实现基于任意大小的内存分配。可简化实现，能够体现其主体思想即可。

 - 参考[linux的slub分配算法/](http://www.ibm.com/developerworks/cn/linux/l-cn-slub/)，在ucore中实现slub分配算法。要求有比较充分的测试用例说明实现的正确性，需要有设计文档。

#### 扩展练习Challenge：硬件的可用物理内存范围的获取方法（思考题）

  - 如果 OS 无法提前知道当前硬件的可用物理内存范围，请问你有何办法让 OS 获取可用物理内存范围？


> Challenges是选做，完成Challenge的同学可单独提交Challenge。完成得好的同学可获得最终考试成绩的加分。

知识点总结和对比：

1. **物理内存管理**：
   - 如果没有适当的物理内存管理，所有程序的地址空间都会冲突。
   - 为了避免每个字节都需要翻译，引入“页”的概念，进行地址翻译。
2. **RISCV架构下的sv39页表机制**：
   - 每页大小为4KB，页表存储虚拟地址和物理地址之间的映射。
   - 虚拟页数量可能远大于物理页。
   - 虚拟地址有64位，但只有低39位是有效的。
   - 地址的最后12位代表页内偏移。
3. **操作系统启动**：
   - bootloader在启动时不直接调用kern_init。
   - 首先调用kern_entry函数，为kern_init建立环境，设置堆栈并建立段映射关系。
   - kern_init函数进行物理内存管理初始化，然后进行中断和异常的初始化。
4. **页表项的构成**：
   - 描述虚拟页如何映射到物理页。
   - sv39中，每个页表项大小为8字节，其中包含保留位、物理页号和映射状态信息等。
   - 页表项还有一些特定的标志位，如Dirty、Accessed、Global等。
5. **多级页表**：
   - 普通页表是一个数组，使用虚拟页号作为索引来查找物理页号。
   - 多级页表可以节省空间，特别是当虚拟地址空间非常大时。
   - 二级页表可以非连续，只需要建立必要的页表项。
6. **satp寄存器**：
   - 存储根页表的起始地址。
   - 高4位存储页表模式。
7. **TLB快表**：
   - TLB是页表的缓存。
   - 修改satp或页表项会导致TLB不同步，需要刷新TLB。